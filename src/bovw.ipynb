{"cells":[{"source":["import cv2\n","import numpy as np\n","import sys\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mimg\n","import os\n","sys.path.append('src')\n","from utilities import load_training_images, load_testing_images\n","from sklearn.cluster import KMeans\n","from sklearn.svm import SVC\n","import random\n","from sklearn.preprocessing import MinMaxScaler\n","%matplotlib inline\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["PATCH_SIZE = (8,8)\n","def extract_patches(img, patch_size):\n","    x_size = patch_size[1]\n","    y_size = patch_size[0]\n","    patches = []\n","    for i in range(int(img.shape[0] / y_size)):\n","        for j in range(int(img.shape[1] / x_size)):\n","            patch = img[i * y_size:(i + 1) * y_size , j * x_size:(j + 1) * x_size]\n","            patches.append(patch)\n","    return patches\n","\n","def extract_features(img):\n","    feature_vectors = []\n","    patches = extract_patches(img, PATCH_SIZE)\n","    for p in patches:\n","        feature_vector = p.flatten() \n","        feature_vectors.append(feature_vector[::4]) # Sampling every 4 px\n","    return np.asarray(feature_vectors)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["(train_images, train_image_classes, class_names) = load_training_images()\n","test_images = load_testing_images()\n","\n","# For testing only\n","sample_indices = np.random.randint(0, len(train_images), 50)\n","train_images = np.array(train_images)[sample_indices]\n","train_image_classes = np.array(train_image_classes)[sample_indices]\n","test_images = random.sample(test_images, 10)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(9,12))\n","for i in range(3):\n","    for j in range(4):\n","        ax[i][j].set_title(class_names[train_image_classes[(3 * i) + j] - 1])\n","        ax[i][j].imshow(train_images[(3 * i) + j], cmap='gray')\n","        ax[i][j].set_xticks([],[])\n","        ax[i][j].set_yticks([],[])\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["train_feature_vectors = []\n","for img in train_images:\n","    features = extract_features(img)\n","    for f in features:\n","         train_feature_vectors.append(f)\n","scaler = MinMaxScaler()\n","train_feature_vectors = scaler.fit_transform(np.asarray(train_feature_vectors))\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["K = 100 # For testing\n","kmeans = KMeans(K).fit(train_feature_vectors)\n","codewords = kmeans.cluster_centers_\n","labels = kmeans.labels_\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["fig, ax = plt.subplots(nrows=1, ncols=20, figsize=(18,3))\n","for i in range(20):\n","    ax[i].imshow(np.reshape(codewords[i], (4,4)), cmap='gray')\n","    ax[i].set_xticks([],[])\n","    ax[i].set_yticks([],[])\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["def build_img_histogram(img, kmeans):\n","    scaler = MinMaxScaler()\n","    features = scaler.fit_transform(extract_features(train_images[i]))\n","    cluster_predict = kmeans.predict(features)\n","    histogram = np.histogram(cluster_predict, bins=range(len(kmeans.cluster_centers_) + 1))[0]\n","    return histogram\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["train_img_histograms = np.zeros((len(train_images), K))\n","for i in range(len(train_images)):\n","    train_img_histograms[i] = build_img_histogram(train_images[i], kmeans)\n","\n","test_img_histograms = np.zeros((len(test_images), K))\n","for i in range(len(test_images)):\n","    test_img_histograms[i] = build_img_histogram(test_images[i], kmeans)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(18,3))\n","hist_1 = train_img_histograms[np.where(train_image_classes == 13)[0],:]\n","for i in range(min(4,len(hist_1))):\n","    ax[i].set_title(class_names[train_image_classes[12] - 1])\n","    ax[i].bar(range(0, K), hist_1[i])\n","\n","fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(18,3))\n","hist_2 = train_img_histograms[np.where(train_image_classes == 6)[0],:]\n","for i in range(min(4,len(hist_2))):\n","    ax[i].set_title(class_names[train_image_classes[5] - 1])\n","    ax[i].bar(range(0, K), hist_2[i])\n","\n","fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(18,3))\n","hist_3= train_img_histograms[np.where(train_image_classes == 15)[0],:]\n","for i in range(min(4,len(hist_3))):\n","    ax[i].set_title(class_names[train_image_classes[14] - 1])\n","    ax[i].bar(range(0, K), hist_3[i])\n","\n","fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(18,3))\n","hist_4= train_img_histograms[np.where(train_image_classes == 4)[0],:]\n","for i in range(min(4,len(hist_4))):\n","    ax[i].set_title(class_names[train_image_classes[4] - 1])\n","    ax[i].bar(range(0, K), hist_4[i])\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["classifiers = SVC()\n","classifiers.fit(train_img_histograms, train_image_classes)\n","predicted = classifiers.predict(test_img_histograms)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["if os.path.exists('run2.txt'):\n","    os.remove('run2.txt')\n","f = open('run2.txt', 'x')\n","for i in range(len(test_img_histograms)):\n","    plt.figure()\n","    img_name = class_names[predicted[i] - 1]\n","    plt.title(img_name)\n","    plt.imshow(test_images[i], cmap='gray')\n","    f = open('run2.txt', 'a')\n","    f.write(f'{i}.jpg {img_name}' + '\\n')"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}